# Phase 3 Load - Quick Reference Card

**Configuration:** 20 parallel workers processing 200,000 users

---

## ğŸ“Š The Numbers (Every Second)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  SUSTAINED LOAD (Typical Case)          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Requests per second:      13            â•‘
â•‘  Concurrent connections:   20            â•‘
â•‘  Response time:            1.5s avg      â•‘
â•‘  Duration:                 4.2 hours     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## â±ï¸ Timeline Breakdown

### Per Second
- **13 API calls complete**
- **13 new API calls start**
- **20 workers always busy**

### Per Minute
- **780 requests sent**
- **800 users processed**
- **28 MB data received**
- **0.4% progress**

### Per Hour
- **46,800 requests sent**
- **48,000 users processed**
- **1.68 GB data received**
- **24% progress**

### Total (4.2 hours)
- **200,000 requests sent**
- **200,000 users processed**
- **7 GB data received**
- **100% complete** âœ“

---

## ğŸŒ Network Load

```
BANDWIDTH (Sustained):
â”œâ”€ Outbound:  73 Kbps   (9 KB/s)
â”œâ”€ Inbound:   3.7 Mbps  (455 KB/s)
â””â”€ Total:     3.77 Mbps (468 KB/s)

PER REQUEST:
â”œâ”€ Request size:   500 bytes
â”œâ”€ Response size:  35 KB
â””â”€ Round trip:     ~35.5 KB
```

---

## ğŸ¯ Load Balancer View

**If CardGenius has 3 backend servers:**

```
Each Backend Server Receives:
â”œâ”€ Connections: 6-7 (of our 20)
â”œâ”€ Requests/sec: 4-5
â”œâ”€ Load share: 33%
â””â”€ Very manageable
```

---

## ğŸ“ˆ Load Pattern

```
Start:  0 â†’ 13 req/s (ramp up in 5 seconds)
Hour 1: 13 req/s sustained â”â”â”â”â”â”â”â”â”â”â”â”â”
Hour 2: 13 req/s sustained â”â”â”â”â”â”â”â”â”â”â”â”â”
Hour 3: 13 req/s sustained â”â”â”â”â”â”â”â”â”â”â”â”â”
Hour 4: 13 req/s sustained â”â”â”â”â”â”â”â”â”â”â”â”â”
End:    13 â†’ 0 req/s (wind down in 2 min)
```

---

## ğŸ”¢ Best/Typical/Worst Case

| Scenario | Req/Sec | Time for 200K |
|----------|---------|---------------|
| **Best** (1.0s response) | 20 | 2.8 hours |
| **Typical** (1.5s response) | 13 | 4.2 hours |
| **Worst** (3.0s response) | 7 | 8.3 hours |

---

## âœ‰ï¸ Email CardGenius (Copy-Paste)

```
We'll be processing 200K users with:
- 13 requests/second sustained
- 20 concurrent connections
- Duration: ~4 hours
- Total: 200,000 API calls
- Bandwidth: 3.7 Mbps inbound

Questions:
1. Is this load acceptable?
2. Any rate limits we should know?
3. Preferred time window?
```

---

## ğŸš¨ Monitor These

### Normal (Green)
```
âœ“ Requests/sec: 10-15
âœ“ Response time: < 3s
âœ“ Error rate: < 1%
âœ“ Progress: 800 users/min
```

### Warning (Yellow)
```
âš  Requests/sec: 5-10
âš  Response time: 3-5s
âš  Error rate: 1-5%
âš  Progress: 400-600 users/min
```

### Critical (Red)
```
âœ— Requests/sec: < 5
âœ— Response time: > 10s
âœ— Error rate: > 5%
âœ— No progress for 5+ min
```

---

## ğŸ’¡ Key Points

1. **Very Predictable:** Steady 13 req/s, no spikes
2. **Very Manageable:** Production APIs handle this easily
3. **Long Duration:** 4+ hours continuous
4. **Coordinate:** Tell CardGenius 48 hours ahead
5. **Start Small:** Test with 5 workers first

---

**Bottom Line:**  
13 requests/second for 4 hours = Very reasonable load



